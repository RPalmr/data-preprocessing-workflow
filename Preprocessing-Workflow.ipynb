{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ This exercise will guide you through the preprocessing workflow. Step by step, feature by feature, you will investigate the dataset and take preprocessing decisions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üå§ We stored the `ML_Houses_dataset.csv` [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset.csv) in the cloud.\n",
    "\n",
    "üëá Run the code down below to load the dataset and features you will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>RoofSurface</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>ChimneyStyle</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>bricks</td>\n",
       "      <td>2</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>874.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>bricks</td>\n",
       "      <td>5</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>castiron</td>\n",
       "      <td>9</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Y</td>\n",
       "      <td>castiron</td>\n",
       "      <td>2</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>Y</td>\n",
       "      <td>bricks</td>\n",
       "      <td>12</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  BedroomAbvGr  KitchenAbvGr  OverallCond  RoofSurface  \\\n",
       "0       1710             3             1            5       1995.0   \n",
       "1       1262             3             1            8        874.0   \n",
       "2       1786             3             1            5       1593.0   \n",
       "3       1717             3             1            5       2566.0   \n",
       "4       2198             4             1            5       3130.0   \n",
       "\n",
       "  GarageFinish CentralAir ChimneyStyle  MoSold  SalePrice  \n",
       "0          RFn          Y       bricks       2     208500  \n",
       "1          RFn          Y       bricks       5     181500  \n",
       "2          RFn          Y     castiron       9     223500  \n",
       "3          Unf          Y     castiron       2     140000  \n",
       "4          RFn          Y       bricks      12     250000  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the dataset\n",
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Selecting some columns of interest\n",
    "selected_features = ['GrLivArea',\n",
    "                     'BedroomAbvGr',\n",
    "                     'KitchenAbvGr',\n",
    "                     'OverallCond',\n",
    "                     'RoofSurface',\n",
    "                     'GarageFinish',\n",
    "                     'CentralAir',\n",
    "                     'ChimneyStyle',\n",
    "                     'MoSold',\n",
    "                     'SalePrice']\n",
    "\n",
    "# Overwriting the \"data\" variable to keep only the columns of interest\n",
    "# Notice the .copy() to copy the values\n",
    "data = data[selected_features].copy()\n",
    "\n",
    "# Showing the first five rows\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Take the time to do a ***preliminary investigation*** of the features by reading the ***dataset description*** available [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset_description.txt). Make sure to refer to it throughout the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è ***Duplicates in datasets cause data leakage.*** \n",
    "\n",
    "üëâ It is important to locate and remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many duplicated rows are there in the dataset ‚ùì\n",
    "\n",
    "<i>Save your answer under variable name `duplicate_count`.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "duplicate_count = data[data.duplicated()].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Remove the duplicates from the dataset. Overwite the dataframe `data`‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/reecepalmer/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/reecepalmer/Code/RPalmr/05-ML/02-Prepare-the-dataset/data-preprocessing-workflow/tests\n",
      "plugins: asyncio-0.19.0, dash-2.14.0, typeguard-2.13.3, anyio-3.6.2, hydra-core-1.3.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_duplicates.py::TestDuplicates::test_dataset_length \u001b[32mPASSED\u001b[0m\u001b[32m           [ 50%]\u001b[0m\n",
      "test_duplicates.py::TestDuplicates::test_duplicate_count \u001b[32mPASSED\u001b[0m\u001b[32m          [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.34s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/duplicates.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed duplicates step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('duplicates',\n",
    "                         duplicates = duplicate_count,\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Print the percentage of missing values for every column of the dataframe. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrLivArea       0.000000\n",
      "BedroomAbvGr    0.000000\n",
      "KitchenAbvGr    0.000000\n",
      "OverallCond     0.000000\n",
      "RoofSurface     0.616438\n",
      "GarageFinish    5.547945\n",
      "CentralAir      0.000000\n",
      "ChimneyStyle    0.000000\n",
      "MoSold          0.000000\n",
      "SalePrice       0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `GarageFinish` ‚ùì\n",
    "\n",
    "Investigate the missing values in `GarageFinish`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using `SimpleImputer` from Scikit-Learn\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è According to the dataset description, the missing values in `GarageFinish` represent a house having no garage. They need to be encoded as such.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "missing_count = data['GarageFinish'].isnull().sum()\n",
    "\n",
    "print(missing_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.GarageFinish.replace(np.nan, 'NoGarage', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RoofSurface`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `RoofSurface` ‚ùì\n",
    "\n",
    "Investigate the missing values in `RoofSurface`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using sklearn's `SimpleImputer`\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `RoofSurface` has a few missing values that can be imputed by the median value.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "missing_count = data['RoofSurface'].isnull().sum()\n",
    "\n",
    "print(missing_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "data['RoofSurface'] = imputer.fit_transform(data['RoofSurface'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ChimneyStyle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `ChimneyStyle` ‚ùì\n",
    "\n",
    "Investigate the missing values in `ChimneyStyle`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "* ‚ö†Ô∏è Be careful: not all missing values are represented as `np.nans`, and Python's `isnull()` only detects `np.nans`...\n",
    "    \n",
    "* ‚ÑπÔ∏è `ChimneyStyle` has a lot of missing values. The description does not touch on what they represent. As such, it is better not to make any assumptions and to drop the column entirely.\n",
    "    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_count = data['ChimneyStyle'].isnull().sum()\n",
    "\n",
    "print(missing_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('ChimneyStyle', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/reecepalmer/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/reecepalmer/Code/RPalmr/05-ML/02-Prepare-the-dataset/data-preprocessing-workflow/tests\n",
      "plugins: asyncio-0.19.0, dash-2.14.0, typeguard-2.13.3, anyio-3.6.2, hydra-core-1.3.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_missing_values.py::TestMissing_values::test_nans \u001b[32mPASSED\u001b[0m\u001b[32m             [ 50%]\u001b[0m\n",
      "test_missing_values.py::TestMissing_values::test_number_of_columns \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.31s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/missing_values.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed missing_values step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì When you are done with handling missing value, print out the percentage of missing values for the entire dataframe ‚ùì\n",
    "\n",
    "You should no longer have missing values !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in the entire dataframe: 0.00%\n"
     ]
    }
   ],
   "source": [
    "percentage_missing = (data.isnull().sum().sum() / (data.shape[0] * data.shape[1])) * 100\n",
    "print(f\"Percentage of missing values in the entire dataframe: {percentage_missing:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all, before scaling...**\n",
    "\n",
    "To understand the effects of scaling and encoding on model performance, let's get a **base score without any data transformation**.\n",
    "\n",
    "‚ùì Cross-validate a linear regression model that predicts `SalePrice` using the other features ‚ùì\n",
    "\n",
    "‚ö†Ô∏è Note that a linear regression model can only handle numeric features. [DataFrame.select_dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html) can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared score: 0.57\n",
      "Standard Deviation of R-squared scores: 0.07\n"
     ]
    }
   ],
   "source": [
    "X = data.select_dtypes(include=['number']).drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "mean_score = scores.mean()\n",
    "std_score = scores.std()\n",
    "\n",
    "print(f\"Mean R-squared score: {mean_score:.2f}\")\n",
    "print(f\"Standard Deviation of R-squared scores: {std_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this score in mind! You will train a new model after data preprocessing in Challenge #2 - see if it improves your average score üòâ\n",
    "\n",
    "üöÄ Now, back to **feature scaling**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `RoofSurface` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `RoofSurface` ‚ùì\n",
    "\n",
    "üëá Investigate `RoofSurface` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data['RoofSurface'] = scaler.fit_transform(data[['RoofSurface']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è Since `RoofSurface` has neither a Gaussian distribution, nor outliers $\\rightarrow$ MinMaxScaler.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GrLivArea`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `GrLivArea` ‚ùì\n",
    "\n",
    "üëá Investigate `GrLivArea` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "data['GrLivArea'] = scaler.fit_transform(data[['GrLivArea']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `GrLivArea` has many outliers $\\rightarrow$ RobustScaler()\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr` ‚ùì\n",
    "\n",
    "üëá Investigate `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr`. Then, chose one of the following scaling techniques:\n",
    "\n",
    "1. MinMax Scaler\n",
    "2. Standard Scaler\n",
    "3. Robust Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr` are ordinal features. There are less than 0.1% of outliers so no need to use _RobustScaler()_. The distribution is not Gaussian, hence no _StandardScaler()_. By elimination, you can confidently choose _MinMaxScaler()_.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>RoofSurface</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.078410</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>0.509386</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.813952</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>0.292046</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.263422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.516802</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.246143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.521380</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.483198</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.761406</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.455002</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GrLivArea  BedroomAbvGr  KitchenAbvGr  OverallCond  RoofSurface  \\\n",
       "count  1460.000000   1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean      0.078410      2.866438      1.046575     5.575342     0.509386   \n",
       "std       0.813952      0.815778      0.220338     1.112799     0.292046   \n",
       "min      -2.263422      0.000000      0.000000     1.000000     0.000000   \n",
       "25%      -0.516802      2.000000      1.000000     5.000000     0.246143   \n",
       "50%       0.000000      3.000000      1.000000     5.000000     0.521380   \n",
       "75%       0.483198      3.000000      1.000000     6.000000     0.761406   \n",
       "max       6.455002      8.000000      3.000000     9.000000     1.000000   \n",
       "\n",
       "            MoSold      SalePrice  \n",
       "count  1460.000000    1460.000000  \n",
       "mean      6.321918  180921.195890  \n",
       "std       2.703626   79442.502883  \n",
       "min       1.000000   34900.000000  \n",
       "25%       5.000000  129975.000000  \n",
       "50%       6.000000  163000.000000  \n",
       "75%       8.000000  214000.000000  \n",
       "max      12.000000  755000.000000  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data[['BedroomAbvGr', 'OverallCond', 'KitchenAbvGr']] = scaler.fit_transform(data[['BedroomAbvGr', 'OverallCond', 'KitchenAbvGr']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/reecepalmer/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/reecepalmer/Code/RPalmr/05-ML/02-Prepare-the-dataset/data-preprocessing-workflow/tests\n",
      "plugins: asyncio-0.19.0, dash-2.14.0, typeguard-2.13.3, anyio-3.6.2, hydra-core-1.3.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 3 items\n",
      "\n",
      "test_scaling.py::TestScaling::test_bedroom_kitchen_condition \u001b[32mPASSED\u001b[0m\u001b[32m      [ 33%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_gr_liv_area \u001b[32mPASSED\u001b[0m\u001b[32m                    [ 66%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_roof_surface \u001b[32mPASSED\u001b[0m\u001b[32m                   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.32s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/scaling.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed scaling step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `GarageFinish`‚ùì\n",
    "\n",
    "üëá Investigate `GarageFinish` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Add the encoding to the dataframe as new colum(s), and remove the original column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "        \n",
    "‚ÑπÔ∏è `GarageFinish` is a multicategorical feature that should be One-hot-encoded. You could also consider an Ordinal Encoding but we would have to know for sure that Unfinished or no garage are definitely worse that rough finished!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RFn', 'Unf', 'Fin', 'NoGarage'], dtype=object)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.GarageFinish.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reecepalmer/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse=False, sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False, sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse=False, sparse_output=False)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GarageFinish_ohe = OneHotEncoder(sparse=False)\n",
    "GarageFinish_ohe.fit(data[['GarageFinish']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GarageFinish_Fin', 'GarageFinish_NoGarage', 'GarageFinish_RFn',\n",
       "       'GarageFinish_Unf'], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GarageFinish_ohe.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[GarageFinish_ohe.get_feature_names_out()] = GarageFinish_ohe.transform(data[['GarageFinish']])\n",
    "data.drop(columns=['GarageFinish'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>RoofSurface</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>GarageFinish_Fin</th>\n",
       "      <th>GarageFinish_NoGarage</th>\n",
       "      <th>GarageFinish_RFn</th>\n",
       "      <th>GarageFinish_Unf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.380070</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.316729</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>208500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.312090</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.069650</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>181500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.497489</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.228124</td>\n",
       "      <td>Y</td>\n",
       "      <td>9</td>\n",
       "      <td>223500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390885</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.442583</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.134029</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.566894</td>\n",
       "      <td>Y</td>\n",
       "      <td>12</td>\n",
       "      <td>250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  BedroomAbvGr  KitchenAbvGr  OverallCond  RoofSurface CentralAir  \\\n",
       "0   0.380070         0.375      0.333333        0.500     0.316729          Y   \n",
       "1  -0.312090         0.375      0.333333        0.875     0.069650          Y   \n",
       "2   0.497489         0.375      0.333333        0.500     0.228124          Y   \n",
       "3   0.390885         0.375      0.333333        0.500     0.442583          Y   \n",
       "4   1.134029         0.500      0.333333        0.500     0.566894          Y   \n",
       "\n",
       "   MoSold  SalePrice  GarageFinish_Fin  GarageFinish_NoGarage  \\\n",
       "0       2     208500               0.0                    0.0   \n",
       "1       5     181500               0.0                    0.0   \n",
       "2       9     223500               0.0                    0.0   \n",
       "3       2     140000               0.0                    0.0   \n",
       "4      12     250000               0.0                    0.0   \n",
       "\n",
       "   GarageFinish_RFn  GarageFinish_Unf  \n",
       "0               1.0               0.0  \n",
       "1               1.0               0.0  \n",
       "2               1.0               0.0  \n",
       "3               0.0               1.0  \n",
       "4               1.0               0.0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding  `CentralAir`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `CentralAir`‚ùì\n",
    "\n",
    "Investigate `CentralAir` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Replace the original column with the newly generated encoded columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `CentralAir` is a binary categorical feature.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "data['CentralAir'] = data['CentralAir'].map({'Y': 1, 'N': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MoSold` - Cyclical engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë®üèª‚Äçüè´ A feature can be numerical (continuous or discrete), categorical or ordinal. But a feature can also be temporal (e.g. quarters, months, days, minutes, ...). \n",
    "\n",
    "Cyclical features like time need some specific preprocessing. Indeed, if you want any Machine Learning algorithm to capture this cyclicity, your cyclical features must be preprocessed in a certain way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Consider the feature `MoSold`, the month on which the house was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     253\n",
       "7     234\n",
       "5     204\n",
       "4     141\n",
       "8     122\n",
       "3     106\n",
       "10     89\n",
       "11     79\n",
       "9      63\n",
       "12     59\n",
       "1      58\n",
       "2      52\n",
       "Name: MoSold, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"MoSold\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many houses were sold in June (6), July (7) and May (5) (Spring/Summer)\n",
    "* Only a few houses were sold in December (12), January (1) and February (2) (~ Fall/Winter)\n",
    "    * But for any Machine Learning model, there is no reason why December (12) and January (1) would be \"close\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ ***How to deal with cyclical features?***\n",
    "\n",
    "1.  Look at the following illustration and read the explanations to distinguish two different months.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/cyclical_feature_engineering.png\" alt=\"Cyclical features\" width=\"1000\">\n",
    "\n",
    "\n",
    "2. Read this [article](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/) for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `MoSold` ‚ùì \n",
    "- Create two new features `sin_MoSold` and `cos_MoSold` which correspond respectively to the sine and cosine of MoSold.\n",
    "- Drop the original column `MoSold`\n",
    "\n",
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "To create a time engineered feature based on a column which gives the second in the day!\n",
    "```python\n",
    "seconds_in_day = 24*60*60\n",
    "\n",
    "df['sin_time'] = np.sin(2*np.pi*df.seconds/seconds_in_day)\n",
    "df['cos_time'] = np.cos(2*np.pi*df.seconds/seconds_in_day)\n",
    "df.drop(columns=['seconds'], inplace=True)\n",
    "\n",
    "df.head()\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data['sin_MoSold'] = np.sin(2 * np.pi * data['MoSold'] / 12)\n",
    "data['cos_MoSold'] = np.cos(2 * np.pi * data['MoSold'] / 12)\n",
    "data.drop(columns=['MoSold'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/reecepalmer/.pyenv/versions/3.10.6/envs/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/reecepalmer/Code/RPalmr/05-ML/02-Prepare-the-dataset/data-preprocessing-workflow/tests\n",
      "plugins: asyncio-0.19.0, dash-2.14.0, typeguard-2.13.3, anyio-3.6.2, hydra-core-1.3.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_encoding.py::TestEncoding::test_central_air \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 25%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_columns \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 50%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_month_sold_features \u001b[32mPASSED\u001b[0m\u001b[32m          [ 75%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_month_sold_features_number \u001b[32mPASSED\u001b[0m\u001b[32m   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.35s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/encoding.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed encoding step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding', dataset = data, new_features = ['sin_MoSold', 'cos_MoSold'])\n",
    "\n",
    "result.write()\n",
    "print(result.check())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Export the preprocessed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Now that the dataset has been preprocessed, execute the code below to export it. You will keep working on it in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/clean_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to ***preprocess a dataset*** !\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
